# Anima

![Anima Logo](https://github.com/lyogavin/Anima/blob/main/anima_logo.png?raw=true)


This is the first open source 33B Chinese LLM, we also support DPO alignment training and we have open source 100k context window. The latest update is AirLLM, a library helps you to infer 70B LLM from just single GPU with just 4GB memory.

ç¬¬ä¸€ä¸ªå¼€æºçš„åŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒäº†åŸºäºDPOçš„å¯¹é½è®­ç»ƒã€‚

æˆ‘ä»¬ä¹Ÿå¼€æºäº†100Kè¾“å…¥çª—å£çš„å¼€æºæ¨¡å‹Anima100Kï¼ŒåŸºäºLlama2ï¼Œå¯å•†ç”¨ã€‚

æœ€æ–°å¼€æºäº†å•å¡è·‘70Bæ¨¡å‹çš„AirLLMã€‚


*Read this in [English](README_en.md).*

<div align="left">

<a href="https://github.com/lyogavin/Anima/stargazers">![GitHub Repo stars](https://img.shields.io/github/stars/lyogavin/Anima?style=social)</a>
[![Downloads](https://static.pepy.tech/personalized-badge/airllm?period=total&units=international_system&left_color=grey&right_color=blue&left_text=downloads)](https://pepy.tech/project/airllm)

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/LianjiaTech/BELLE/blob/main/LICENSE)
[![Generic badge](https://img.shields.io/badge/wechat-Anima-brightgreen?logo=wechat)](https://static.aicompose.cn/static/wecom_barcode.png?t=1671918938)
[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/lyogavin/Anima33B-merged)
[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/lyogavin/Anima-7B-100K)
[![Discord](https://img.shields.io/discord/1175437549783760896?logo=discord&color=7289da
)](https://discord.gg/2xffU5sn)
[![PyPI - AirLLM](https://img.shields.io/pypi/format/airllm?logo=pypi&color=3571a3)
](https://pypi.org/project/airllm/)
[![Website](https://img.shields.io/website?up_message=blog&url=https%3A%2F%2Fmedium.com%2F%40lyo.gavin&logo=medium&color=black)](https://medium.com/@lyo.gavin)
[![Support me on Patreon](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fshieldsio-patreon.vercel.app%2Fapi%3Fusername%3Dgavinli%26type%3Dpatrons&style=flat)](https://patreon.com/gavinli)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/lyogavin?logo=GitHub&color=lightgray)](https://github.com/sponsors/lyogavin)

</div>

## ğŸ”„ æ›´æ–° Updates

[2024/04/20] [AirLLM](https://github.com/lyogavin/Anima/tree/main/air_llm) supports Llama3 natively already. Run Llama3 70B on 4GB single GPU.

AirLLMå¤©ç„¶æ”¯æŒLlama3 70Bã€‚4GBæ˜¾å­˜è¿è¡ŒLlama3 70Bå¤§æ¨¡å‹ã€‚

[2024/03/07] Open source: Latte text2video Training - Train your own SORA!

æœ€æ¥è¿‘SORAçš„å¼€æºæ¨¡å‹æ¥äº†ï¼[è®­ç»ƒä½ è‡ªå·±çš„SORA](https://github.com/lyogavin/train_your_own_sora)

[2023/11/17] Open source: AirLLM, inference 70B LLM with 4GB single GPU.

å¼€æºAirLLMï¼Œå•å¡4GBæ˜¾å­˜è·‘70Bå¤§æ¨¡å‹ï¼Œæ— éœ€é‡åŒ–ï¼Œæ— éœ€æ¨¡å‹å‹ç¼©

[2023/09/06] open source 100K context window Llama2 based LLM

æ›´æ–°æ”¯æŒ100k ä¸Šä¸‹æ–‡çš„åŸºäºLlama2çš„å¯å•†ç”¨å¤§æ¨¡å‹

[2023/06/29] Open source alignment training based on DPO+QLORA

æ›´æ–°åŸºäºDPO+QLoRAçš„Human Feedbackè®­ç»ƒ

[2023/06/12] Open source the first 33B Chinese Large language model

å¼€æºäº†ç¬¬ä¸€ä¸ªåŸºäºQLoRAçš„ä¸­æ–‡33Bå¤§è¯­è¨€æ¨¡å‹


## AirLLM, inference 70B LLM with 4GB single GPU

AirLLM optimizes inference memory usage, allowing 70B large language models to run inference on a single 4GB GPU card. No quantization, distillation, pruning or other model compression techniques that would result in degraded model performance are needed.

AirLLMä¼˜åŒ–inferenceå†…å­˜ï¼Œ4GBå•å¡GPUå¯ä»¥è¿è¡Œ70Bå¤§è¯­è¨€æ¨¡å‹æ¨ç†ã€‚ä¸éœ€è¦ä»»ä½•æŸå¤±æ¨¡å‹æ€§èƒ½çš„é‡åŒ–å’Œè’¸é¦ï¼Œå‰ªæç­‰æ¨¡å‹å‹ç¼©ã€‚


Find out more [Here](https://github.com/lyogavin/Anima/tree/main/air_llm)ã€‚

##  Train your own SORA: Open source: Latte text2video Training

Train your own SORA:

Check out here: [https://github.com/lyogavin/train_your_own_sora](https://github.com/lyogavin/train_your_own_sora)

## 100K context length LLM

We released the new Anima open source 7B model, supporting an input window length of 100K! Itâ€™s based on LLama2, so available for commercial use!

With specifically curated long text question answering training data for the 100K input length, and a lot of memory optimizations, we enabled the LLama2 model to scale to 100K input length.


å½“è¾“å…¥é•¿åº¦æ”¯æŒ100kï¼Œä½ ç”šè‡³å¯ä»¥æŠŠæ•´ä¸ªçŸ¥è¯†åº“éƒ½æ”¾å…¥Promptäº¤ç»™æ¨¡å‹ã€‚æˆ–è€…å¯ä»¥æŠŠä¸€æœ¬ä¹¦ç›´æ¥æ”¾åˆ°Prompté‡Œè¾¹ã€‚å†ä¹Ÿä¸ç”¨å„ç§è´¹åŠ²çš„å‘é‡åŒ–ï¼Œæ–‡æœ¬åˆ†å‰²ã€‚ã€‚ã€‚ã€‚

æˆ‘ä»¬å †äº†å„ç§æœ€æ–°çš„çŒ›æ–™ï¼š[XEntropy](https://github.com/NVIDIA/apex/tree/master/apex/contrib/xentropy)ï¼Œ[Paged 8bit Adamw](https://github.com/TimDettmers/bitsandbytes), [LORA](https://github.com/huggingface/peft), [Flashattention2](https://github.com/Dao-AILab/flash-attention)ï¼Œå¹¶ä¸”ä¸“é—¨é’ˆå¯¹é•¿è¾“å…¥å¯¹äºtrainingå’ŒInferenceä»£ç éƒ½åšäº†ä¿®æ”¹å®šåˆ¶ï¼Œä½¿å¾—å•å¡100Gå°±å¯ä»¥è®­ç»ƒ100kçª—å£ã€‚å•å¡40Gå°±å¯ä»¥è¿›è¡Œæ¨ç†ã€‚

è®­ç»ƒæ•°æ®ä¸Šï¼Œä»å‡ åç§å…¬å¼€æ•°æ®é›†ä¸­ç²¾é€‰äº†ä¸“é—¨é’ˆå¯¹é•¿è¾“å…¥çš„30kï½100ké•¿åº¦çš„é•¿æ–‡æœ¬è®­ç»ƒæ•°æ®ï¼Œä¸“é—¨é’ˆå¯¹100Kè¾“å…¥å¯¹æ¨¡å‹è¿›è¡Œäº†è®­ç»ƒã€‚

Find out more [Here](https://github.com/lyogavin/Anima/tree/main/anima_100k)ã€‚

[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/lyogavin/Anima-7B-100K) 


## Anima 33B Chinese

We believe the future of AI will be fully open and democratized. AI should be a tool thatâ€™s accessible to everyone, instead of only the big monopolies(some of them have the term â€œopenâ€ in their names ğŸ˜† .). QLoRA might be an important step towards that future. We want to make some small contribution to the historical process of democratization of AI, we are open sourcing the 33B QLoRA model we trained: all the model parameters, code, datasets and evaluations are opened! ğŸ¤—


å› æ­¤æˆ‘ä»¬è®¤ä¸º[QLoRA](https://arxiv.org/abs/2305.14314) çš„å·¥ä½œå¾ˆé‡è¦ï¼Œé‡è¦åˆ°å¯èƒ½æ˜¯ä¸ªGame Changerã€‚é€šè¿‡QLoRAçš„ä¼˜åŒ–æ–¹æ³•ï¼Œç¬¬ä¸€æ¬¡è®©33Bè§„æ¨¡çš„æ¨¡å‹å¯ä»¥æ¯”è¾ƒæ°‘ä¸»åŒ–çš„ï¼Œæ¯”è¾ƒä½æˆæœ¬çš„finetuneè®­ç»ƒï¼Œå¹¶ä¸”æ™®åŠä½¿ç”¨ã€‚æˆ‘ä»¬è®¤ä¸º33Bæ¨¡å‹æ—¢å¯ä»¥å‘æŒ¥å¤§è§„æ¨¡æ¨¡å‹çš„æ¯”è¾ƒå¼ºçš„reasoningèƒ½åŠ›ï¼Œåˆå¯ä»¥é’ˆå¯¹ç§æœ‰ä¸šåŠ¡é¢†åŸŸæ•°æ®è¿›è¡Œçµæ´»çš„finetuneè®­ç»ƒæå‡å¯¹äºLLMçš„æ§åˆ¶åŠ›ã€‚

Find out more [Here](https://github.com/lyogavin/Anima/tree/main/training)ã€‚


[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/lyogavin/Anima33B-merged) 


## Alignment training based on DPO and QLoRA

We open sourced latest alignment techinque - DPO.

Animaæ¨¡å‹åˆå¼€æºäº†åŸºäºQLoRAçš„æœ€æ–°çš„DPOæŠ€æœ¯ã€‚

DPOæ˜¯æœ€æ–°çš„æœ€é«˜æ•ˆçš„RLHFè®­ç»ƒæ–¹æ³•ã€‚RLHFä¸€ç›´æ˜¯ç”Ÿæˆå¼AIè®­ç»ƒçš„è€å¤§éš¾é—®é¢˜ï¼Œä¹Ÿè¢«è®¤ä¸ºæ˜¯OpenAIçš„å‹ç®±åº•ç‹¬å®¶ç§˜ç¬ˆã€‚DPOæŠ€æœ¯æ”¹å˜äº†è¿™ä¸€åˆ‡ï¼Œè®©RLHFå½»åº•å‚»ç“œåŒ–ï¼

æˆ‘ä»¬å¼€æºäº†RLHFçš„ä½æˆæœ¬QLoRAçš„å®ç°ï¼Œä¸€å°GPUæœºå™¨å°±å¯ä»¥è®­ç»ƒ33Bæ¨¡å‹çš„DPOï¼

Find out more [here](https://github.com/lyogavin/Anima/tree/main/rlhf)ã€‚

[![Generic badge](https://img.shields.io/badge/ğŸ¤—-Huggingface%20Repo-green.svg)](https://huggingface.co/lyogavin/Anima33B-DPO-Belle-1k-merged) 


## Stay Connected with Us

### Wechat å¾®ä¿¡å…¬ä¼—å·

æ‰«ç ï¼š

![group](https://github.com/lyogavin/Anima/blob/main/assets/wechat_pub_account.jpg?raw=true)


### Wechat group å¾®ä¿¡ç¾¤

æ‰«ç è¿›ç¾¤ï¼š

<img src="https://github.com/lyogavin/Anima/blob/main/assets/wechat_group.png?raw=true" alt="group" style="width:260px;"/>

### Discord

[![Discord](https://img.shields.io/discord/1175437549783760896?logo=discord&color=7289da
)](https://discord.gg/2xffU5sn)

### Blog

[![Website](https://img.shields.io/website?up_message=blog&url=https%3A%2F%2Fmedium.com%2F%40lyo.gavin&logo=medium&color=black)](https://medium.com/@lyo.gavin)


## Contribution å‚ä¸è´¡çŒ®

Buy me a coffee please! æ¬¢è¿å¤§å®¶å‚ä¸è´¡çŒ®æœ¬é¡¹ç›® ğŸ™

**å¦‚æœä½ å–œæ¬¢æˆ‘ä»¬çš„é¡¹ç›®ï¼Œè¯·å¸®å¿™ç‚¹ä¸ªâ­å§!**

[!["Buy Me A Coffee"](https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png)](https://bmc.link/lyogavinQ)



## âœï¸ è‰¾å†™ç§‘æŠ€ & Anima AI

This work is from [Anima AI LLC](https://animaai.cloud) and [aiwrite.ai](https://aiwrite.ai).

æ­¤å·¥ä½œæ¥è‡ªäº[è‰¾å†™ç§‘æŠ€](https://aiwrite.ai)ï¼Œ [Anima AI](https://animaai.cloud)ã€‚



